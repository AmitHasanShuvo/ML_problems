{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diabetes dataset\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes_dataset = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the input and target variables\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = diabetes_dataset['data']\n",
    "targets = diabetes_dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data set into training and test sets\n",
    "\n",
    "train_data, test_data, train_targets, test_targets = train_test_split(data, targets, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(train_data.shape[1],)),\n",
    "    Dense(64,activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)        \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "    \n",
    "model.compile(loss='mse', optimizer=\"adam\", metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Custom Callback\n",
    "\n",
    "We define our custom callback using the logs dictionary to access the loss and metric values.\n",
    "The logs dictionary stores the loss value, along with all of the metrics we are using at the end of a batch or epoch.\n",
    "\n",
    "We can incorporate information from the logs dictionary into our own custom callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossAndMetricCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    # Print the loss after every second batch in the training set\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        if batch%2 == 0:\n",
    "            print('\\n After batch {}, the loss is {:7.2f}'.format(batch, logs['loss']))\n",
    "    \n",
    "    # Print the loss after each batch in the test set\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        print('\\n After batch {}, the loss is {:7.2f}'.format(batch, logs['loss']))\n",
    "    \n",
    "    # Print the loss and mae after each epoch in the training set\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('\\n Epoch {}: Average Loss is {:7.2f}, mean absolute error is {:7.2f}'.format(epoch, logs['loss']\n",
    "                                                                                            , logs['mae']))\n",
    "    # Notify the user when prediction has finished after each batch\n",
    "    def on_predict_batch_end(self, batch, logs=None):\n",
    "        print('Finished prediction on batch {}'.format(batch))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " After batch 0, the loss is 26861.43\n",
      "\n",
      " After batch 2, the loss is 25043.65\n",
      "\n",
      " After batch 4, the loss is 33681.30\n",
      "\n",
      " After batch 6, the loss is 25810.09\n",
      "\n",
      " After batch 8, the loss is 31782.19\n",
      "\n",
      " After batch 10, the loss is 31828.43\n",
      "\n",
      " After batch 12, the loss is 30626.94\n",
      "\n",
      " Epoch 0: Average Loss is 28486.52, mean absolute error is  150.75\n",
      "\n",
      " After batch 0, the loss is 37456.84\n",
      "\n",
      " After batch 2, the loss is 34291.33\n",
      "\n",
      " After batch 4, the loss is 27507.87\n",
      "\n",
      " After batch 6, the loss is 28610.87\n",
      "\n",
      " After batch 8, the loss is 27326.74\n",
      "\n",
      " After batch 10, the loss is 24776.57\n",
      "\n",
      " After batch 12, the loss is 23980.45\n",
      "\n",
      " Epoch 1: Average Loss is 27674.95, mean absolute error is  148.04\n",
      "\n",
      " After batch 0, the loss is 30669.45\n",
      "\n",
      " After batch 2, the loss is 26658.01\n",
      "\n",
      " After batch 4, the loss is 28809.33\n",
      "\n",
      " After batch 6, the loss is 17275.17\n",
      "\n",
      " After batch 8, the loss is 22006.08\n",
      "\n",
      " After batch 10, the loss is 22990.02\n",
      "\n",
      " After batch 12, the loss is 27064.24\n",
      "\n",
      " Epoch 2: Average Loss is 25659.10, mean absolute error is  141.48\n",
      "\n",
      " After batch 0, the loss is 21862.13\n",
      "\n",
      " After batch 2, the loss is 22384.04\n",
      "\n",
      " After batch 4, the loss is 26332.66\n",
      "\n",
      " After batch 6, the loss is 19852.80\n",
      "\n",
      " After batch 8, the loss is 24885.92\n",
      "\n",
      " After batch 10, the loss is 18797.20\n",
      "\n",
      " After batch 12, the loss is 11627.58\n",
      "\n",
      " Epoch 3: Average Loss is 21694.74, mean absolute error is  127.63\n",
      "\n",
      " After batch 0, the loss is 25654.10\n",
      "\n",
      " After batch 2, the loss is 22443.72\n",
      "\n",
      " After batch 4, the loss is 18844.11\n",
      "\n",
      " After batch 6, the loss is 14554.24\n",
      "\n",
      " After batch 8, the loss is 6479.79\n",
      "\n",
      " After batch 10, the loss is 10155.26\n",
      "\n",
      " After batch 12, the loss is 10704.11\n",
      "\n",
      " Epoch 4: Average Loss is 15542.02, mean absolute error is  102.66\n",
      "\n",
      " After batch 0, the loss is 12087.22\n",
      "\n",
      " After batch 2, the loss is 17719.02\n",
      "\n",
      " After batch 4, the loss is 8395.67\n",
      "\n",
      " After batch 6, the loss is 10625.23\n",
      "\n",
      " After batch 8, the loss is 9337.51\n",
      "\n",
      " After batch 10, the loss is 4413.69\n",
      "\n",
      " After batch 12, the loss is 4926.38\n",
      "\n",
      " Epoch 5: Average Loss is 9288.14, mean absolute error is   75.88\n",
      "\n",
      " After batch 0, the loss is 8149.10\n",
      "\n",
      " After batch 2, the loss is 10134.35\n",
      "\n",
      " After batch 4, the loss is 3932.54\n",
      "\n",
      " After batch 6, the loss is 5837.61\n",
      "\n",
      " After batch 8, the loss is 4708.69\n",
      "\n",
      " After batch 10, the loss is 7853.23\n",
      "\n",
      " After batch 12, the loss is 10553.28\n",
      "\n",
      " Epoch 6: Average Loss is 6366.93, mean absolute error is   62.53\n",
      "\n",
      " After batch 0, the loss is 4180.15\n",
      "\n",
      " After batch 2, the loss is 4245.58\n",
      "\n",
      " After batch 4, the loss is 6821.84\n",
      "\n",
      " After batch 6, the loss is 5021.78\n",
      "\n",
      " After batch 8, the loss is 4499.48\n",
      "\n",
      " After batch 10, the loss is 2955.11\n",
      "\n",
      " After batch 12, the loss is 5623.19\n",
      "\n",
      " Epoch 7: Average Loss is 5039.81, mean absolute error is   56.11\n",
      "\n",
      " After batch 0, the loss is 4975.33\n",
      "\n",
      " After batch 2, the loss is 3923.98\n",
      "\n",
      " After batch 4, the loss is 2200.68\n",
      "\n",
      " After batch 6, the loss is 2790.57\n",
      "\n",
      " After batch 8, the loss is 5831.39\n",
      "\n",
      " After batch 10, the loss is 4931.64\n",
      "\n",
      " After batch 12, the loss is 2762.16\n",
      "\n",
      " Epoch 8: Average Loss is 4586.68, mean absolute error is   53.29\n",
      "\n",
      " After batch 0, the loss is 2443.95\n",
      "\n",
      " After batch 2, the loss is 4869.01\n",
      "\n",
      " After batch 4, the loss is 4987.42\n",
      "\n",
      " After batch 6, the loss is 5287.33\n",
      "\n",
      " After batch 8, the loss is 3346.99\n",
      "\n",
      " After batch 10, the loss is 5509.54\n",
      "\n",
      " After batch 12, the loss is 4922.23\n",
      "\n",
      " Epoch 9: Average Loss is 4211.71, mean absolute error is   50.94\n",
      "\n",
      " After batch 0, the loss is 4201.25\n",
      "\n",
      " After batch 2, the loss is 4473.60\n",
      "\n",
      " After batch 4, the loss is 1332.87\n",
      "\n",
      " After batch 6, the loss is 3779.52\n",
      "\n",
      " After batch 8, the loss is 2513.93\n",
      "\n",
      " After batch 10, the loss is 3552.85\n",
      "\n",
      " After batch 12, the loss is 3646.26\n",
      "\n",
      " Epoch 10: Average Loss is 3353.88, mean absolute error is   46.31\n",
      "\n",
      " After batch 0, the loss is 3505.73\n",
      "\n",
      " After batch 2, the loss is 7336.79\n",
      "\n",
      " After batch 4, the loss is 3837.32\n",
      "\n",
      " After batch 6, the loss is 2119.19\n",
      "\n",
      " After batch 8, the loss is 3676.54\n",
      "\n",
      " After batch 10, the loss is 2977.16\n",
      "\n",
      " After batch 12, the loss is 3280.76\n",
      "\n",
      " Epoch 11: Average Loss is 3491.40, mean absolute error is   46.75\n",
      "\n",
      " After batch 0, the loss is 2100.60\n",
      "\n",
      " After batch 2, the loss is 2748.96\n",
      "\n",
      " After batch 4, the loss is 2363.06\n",
      "\n",
      " After batch 6, the loss is 2029.85\n",
      "\n",
      " After batch 8, the loss is 2702.34\n",
      "\n",
      " After batch 10, the loss is 3218.87\n",
      "\n",
      " After batch 12, the loss is 4640.15\n",
      "\n",
      " Epoch 12: Average Loss is 3218.97, mean absolute error is   45.59\n",
      "\n",
      " After batch 0, the loss is 3185.95\n",
      "\n",
      " After batch 2, the loss is 3360.75\n",
      "\n",
      " After batch 4, the loss is 2278.89\n",
      "\n",
      " After batch 6, the loss is 4353.74\n",
      "\n",
      " After batch 8, the loss is 4077.81\n",
      "\n",
      " After batch 10, the loss is 2779.51\n",
      "\n",
      " After batch 12, the loss is 2416.10\n",
      "\n",
      " Epoch 13: Average Loss is 3035.63, mean absolute error is   45.04\n",
      "\n",
      " After batch 0, the loss is 3213.59\n",
      "\n",
      " After batch 2, the loss is 2156.96\n",
      "\n",
      " After batch 4, the loss is 2806.65\n",
      "\n",
      " After batch 6, the loss is 3290.32\n",
      "\n",
      " After batch 8, the loss is 5143.87\n",
      "\n",
      " After batch 10, the loss is 3199.58\n",
      "\n",
      " After batch 12, the loss is 5767.91\n",
      "\n",
      " Epoch 14: Average Loss is 3375.39, mean absolute error is   46.32\n",
      "\n",
      " After batch 0, the loss is 2901.55\n",
      "\n",
      " After batch 2, the loss is 3399.83\n",
      "\n",
      " After batch 4, the loss is 2228.83\n",
      "\n",
      " After batch 6, the loss is 3163.30\n",
      "\n",
      " After batch 8, the loss is 2855.10\n",
      "\n",
      " After batch 10, the loss is 2284.26\n",
      "\n",
      " After batch 12, the loss is 4737.24\n",
      "\n",
      " Epoch 15: Average Loss is 3043.17, mean absolute error is   44.39\n",
      "\n",
      " After batch 0, the loss is 3185.83\n",
      "\n",
      " After batch 2, the loss is 4209.30\n",
      "\n",
      " After batch 4, the loss is 2148.13\n",
      "\n",
      " After batch 6, the loss is 3196.47\n",
      "\n",
      " After batch 8, the loss is 2596.12\n",
      "\n",
      " After batch 10, the loss is 2607.46\n",
      "\n",
      " After batch 12, the loss is 1624.41\n",
      "\n",
      " Epoch 16: Average Loss is 2908.32, mean absolute error is   43.96\n",
      "\n",
      " After batch 0, the loss is 3400.70\n",
      "\n",
      " After batch 2, the loss is 3361.23\n",
      "\n",
      " After batch 4, the loss is 1903.21\n",
      "\n",
      " After batch 6, the loss is 1925.28\n",
      "\n",
      " After batch 8, the loss is 1910.42\n",
      "\n",
      " After batch 10, the loss is 3624.79\n",
      "\n",
      " After batch 12, the loss is 1743.14\n",
      "\n",
      " Epoch 17: Average Loss is 2782.44, mean absolute error is   42.57\n",
      "\n",
      " After batch 0, the loss is 3256.16\n",
      "\n",
      " After batch 2, the loss is 1474.71\n",
      "\n",
      " After batch 4, the loss is 2124.61\n",
      "\n",
      " After batch 6, the loss is 3031.01\n",
      "\n",
      " After batch 8, the loss is 3946.40\n",
      "\n",
      " After batch 10, the loss is 2508.08\n",
      "\n",
      " After batch 12, the loss is 1962.18\n",
      "\n",
      " Epoch 18: Average Loss is 2831.55, mean absolute error is   42.59\n",
      "\n",
      " After batch 0, the loss is 2642.68\n",
      "\n",
      " After batch 2, the loss is 3629.31\n",
      "\n",
      " After batch 4, the loss is 2210.78\n",
      "\n",
      " After batch 6, the loss is 2558.69\n",
      "\n",
      " After batch 8, the loss is 2745.57\n",
      "\n",
      " After batch 10, the loss is 3032.10\n",
      "\n",
      " After batch 12, the loss is 5082.09\n",
      "\n",
      " Epoch 19: Average Loss is 2763.42, mean absolute error is   42.49\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "history = model.fit(train_data, train_targets, epochs=20,\n",
    "                    batch_size=32, callbacks=[LossAndMetricCallback()], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " After batch 0, the loss is 8686.03\n",
      "\n",
      " After batch 1, the loss is 12774.32\n",
      "\n",
      " After batch 2, the loss is 12887.88\n",
      "\n",
      " After batch 3, the loss is 16177.07\n",
      "\n",
      " After batch 4, the loss is 10216.00\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "model_eval = model.evaluate(test_data, test_targets, batch_size=10, \n",
    "                            callbacks=[LossAndMetricCallback()], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished prediction on batch 0\n",
      "Finished prediction on batch 1\n",
      "Finished prediction on batch 2\n",
      "Finished prediction on batch 3\n",
      "Finished prediction on batch 4\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from the model\n",
    "\n",
    "model_pred = model.predict(test_data, batch_size=10,\n",
    "                           callbacks=[LossAndMetricCallback()], verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduler:\n",
    "\n",
    "We are going to define a callback to change the learning rate of the optimiser of a model during training. We will do this by specifying the epochs and new learning rates where we would like it to be changed.\n",
    "\n",
    "First we define the auxillary function that returns the learning rate for each epoch based on our schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the learning rate schedule. The tuples below are (start_epoch, new_lr)\n",
    "\n",
    "\n",
    "lr_schedule = [\n",
    "    (4, 0.03), (7, 0.02), (11, 0.005), (15, 0.007)\n",
    "]\n",
    "\n",
    "def get_new_epoch_lr(epoch, lr):\n",
    "    # Checks to see if the new input epoch is listed in the learning rate schedule and if so, \n",
    "    # returns learning rate lr_schedule\n",
    "    epoch_in_sched = [i for i in range(len(lr_schedule)) if lr_schedule[i][0] == int(epoch)]\n",
    "    \n",
    "    if len(epoch_in_sched)>0:\n",
    "        # if the epoch exists in the lr_schedule, we return the corresponding learning rate\n",
    "        return lr_schedule[epoch_in_sched[0]][1]\n",
    "    else:\n",
    "        # return the existing learning rate\n",
    "        return lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the custom callback\n",
    "\n",
    "class LRScheduler(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, new_lr):\n",
    "        super(LRScheduler, self).__init__()\n",
    "        # Add the new learning rate function to our callback\n",
    "        self.new_lr = new_lr\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # Make sure that the optimizer we have chosen has a learning rate, raise an error if not\n",
    "        if not hasattr(self.model.optimizer, 'lr'):\n",
    "            raise ValueError('Error: Optimizer does not have a learning rate')\n",
    "        \n",
    "        # Get the current learning rate\n",
    "        curr_rate = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n",
    "        \n",
    "        # Call the auxilliary function to get the scheduled learning rate for the current epoch\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
